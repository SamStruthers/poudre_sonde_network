---
title: "post_2022"
author: "Katie Willi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

library(lubridate)

library(rvest)

library(dygraphs)
```

#### Pulling up field notes

```{r}
# WHEN DATA WAS STORED ON GOOGLE DRIVE:
# field_notes <- read_sheet("https://docs.google.com/spreadsheets/d/11Gc1eS1wt9NrU12hWw1mUl25ixKZrTndIVCsvD4UKao/edit#gid=0") %>%
#   mutate(start_time_mst = (substr(start_time_mst, 12, 19)),
#          DT = round_date(as_datetime(paste0(date,' ',start_time_mst), tz="MST"), '15 mins'))

# NOW, ON MICROSOFT ONEDRIVE:

field_notes <- readxl::read_excel('data/sensor_field_notes.xlsx') %>%
  mutate(DT = ((paste0(date, " ", start_time_mst))))
```

#### Downloading calibration reports

```{r}
# setwd("C:/Users/katie/Documents/0_My_Git/poudre_sonde_network/data/cal_reports")
# 
# #folder <- drive_get(as_id('https://drive.google.com/drive/folders/1XZwrnSaqd7o9GzfaYxdXdZtpZ_vEyixF'))
# 
# cal_files <- drive_ls(folder, type = "html")
# 
# walk(cal_files$id, ~ drive_download(as_id(.x)))

cal_files <- list.files("data/calibration_reports", pattern=".html")

cal_table <- vector("list", length = length(cal_files)) 

# TURN THIS INTO A FOR LOOP

for(i in 1:length(cal_table)){

cal <- rvest::read_html(paste0("data/calibration_reports/", cal_files[i])) %>%
  rvest::html_nodes('div') %>%
  rvest::html_text() %>%
  as_tibble()

rdo <- cal %>% filter(grepl("RDO",value)) %>% pull() %>% str_replace_all(., " ", "")

ph_orp <- cal %>% filter(grepl("pH/ORP",value)) %>% pull() %>% str_replace_all(., " ", "")

conductivity <- cal %>% filter(grepl("Conductivity",value)) %>% pull() %>% str_replace_all(., " ", "")

turbidity <- cal %>% filter(grepl("Turbidity",value)) %>% pull() %>% str_replace_all(., " ", "")

time_mst <- paste0(str_sub(cal_files[i], -13,-12),":",str_sub(cal_files[i], -11,-10))

date <- paste0(str_sub(cal_files[i], -22,-19),"-",str_sub(cal_files[i], -18,-17),"-",str_sub(cal_files[i],-16,-15))

cal_table[[i]] <- tibble(site=sub("\\_.*", "",cal_files[i]),
                     dt=(paste0(date," ",time_mst)),
                     
                     #Dissolved Oxygen
                     rdo_slope=str_match(rdo, "Slope\\s*(.*?)\\s*Offset")[,2],
                     rdo_offset=str_match(rdo, "Offset\\s*(.*?)\\s*mg/L")[,2],
                     rdo_100=str_match(rdo, "PreMeasurement\\s*(.*?)\\s*%SatPost")[,2],
                     rdo_conc=str_match(rdo, "Concentration\\s*(.*?)\\s*mg/LPreMeasurement")[,2],
                     rdo_temp=str_match(rdo, "Temperature\\s*(.*?)\\s*°C")[,2],
                     rdo_pressure=str_match(rdo, "Pressure\\s*(.*?)\\s*mbar")[,2],
                     
                     #pH
                     ph_slope_pre=str_match(ph_orp, "Offset1Slope\\s*(.*?)\\s*mV/pH")[,2],
                     ph_offset_pre=str_match(ph_orp, "mV/pHOffset\\s*(.*?)\\s*mVSlopeandOffset2")[,2],
                     ph_slope_post=str_match(ph_orp, "Offset2Slope\\s*(.*?)\\s*mV/pH")[,2],
                     ph_offset_post=str_match(ph_orp, paste0(ph_slope_post,"mV/pHOffset\\s*(.*?)\\s*mVORPORP"))[,2],
                     # pH needs work. There is no consistent wording to grab the pH mV value...
                     ph_7=ifelse(is.numeric((str_match(ph_orp, "PostMeasurementpH7.00pHpHmV\\s*(.*?)\\s*mV")[,2])), str_match(ph_orp, "PostMeasurementpH7.00pHpHmV\\s*(.*?)\\s*mV")[,2],
                                 "reall bad"),
                     
                     #ORP
                     orp_offset=ifelse(is.na(str_match(ph_orp, "Zobell'sOffset\\s*(.*?)\\s*mVTemperature")[,2]),
                            str_match(ph_orp, "ZoBell'sOffset\\s*(.*?)\\s*mVTemperature")[,2],
                            str_match(ph_orp, "Zobell'sOffset\\s*(.*?)\\s*mVTemperature")[,2]),
                     
                     #Conductivity
                     tds_conversion_ppm=str_match(conductivity, "TDSConversionFactor(ppm)\\s*(.*?)\\s*CellConstant")[,2],
                     cond_cell_constant=str_match(conductivity, "CellConstant\\s*(.*?)\\s*ReferenceTemperature")[,2],
                     cond_pre=str_match(conductivity,paste0(str_match(conductivity,
                        "PreMeasurementActual\\s*(.*?)\\s*SpecificConductivity")[,2],"SpecificConductivity\\s*(.*?)\\s*µS/cmPost"))[,2],
                     cond_post=str_match(conductivity,paste0(str_match(conductivity,
                        "PostMeasurementActual\\s*(.*?)\\s*SpecificConductivity")[,2],"SpecificConductivity\\s*(.*?)\\s*µS/cm"))[,2],
                     
                     #Turbidity
                     ntu_slope=str_match(turbidity, "Slope\\s*(.*?)\\s*Offset")[,2],
                     ntu_offset=str_match(turbidity, "Offset\\s*(.*?)\\s*NTU")[,2],
                     ntu_10=str_match(turbidity, "CalibrationPoint1PreMeasurement\\s*(.*?)\\s*NTUPost")[,2],
                     ntu_100=str_match(turbidity, "CalibrationPoint2PreMeasurement\\s*(.*?)\\s*NTUPost")[,2],
                     
                     #Factory Defaults
                     factory_defaults= paste0(ifelse(is.na(ntu_slope),"Turbidity ",""),
                                  ifelse(is.na(rdo_slope),"RDO ",""),
                                  ifelse(is.na(ph_slope_post),"pH ",""),
                                  ifelse(is.na(orp_offset),"ORP ",""),
                                  ifelse(is.na(cond_post),"Conductivity ","")))
}

cal_table <- bind_rows(cal_table) %>%
  distinct(.keep_all = TRUE)
```

#### Downloading sonde data

Html reader functions
```{r}
# from HydroVu, on the cloud:
hydrovu_reader <- function(file) {
    
    raw_data <- rvest::read_html(file) %>%
      rvest::html_node('table') %>%
      rvest::html_table() %>%
      slice(-1:-8) %>%
      janitor::row_to_names(row_number = 1) 
}

# from AquaTROLL 500/600, in the field:
troll_reader <- function(file) {
  
  raw_data <- rvest::read_html(file) %>%
    rvest::html_node('table') %>%
    rvest::html_table() %>%
    slice(-1:-25) %>%
    janitor::row_to_names(row_number = 1) 
}

# from VuLink, in the field:
vulink_reader <- function(file) {
  
  raw_data <- rvest::read_html(file) %>%
    rvest::html_node('table') %>%
    rvest::html_table() %>%
    slice(-1:-31) %>%
    janitor::row_to_names(row_number = 1) 
}
```

# Legacy

So far in 2022, all data has been sent to HydroVu. This location encountered several issues this field season: sensor pulled 2022-05-24 due to fears that itsinfrastructure would wash away. Sensor was re-deployed 2022-06-01, but was then pulled out due to tech issues 2022-07-08. Sometime between then and 2022-07-12, turbidity sensor broke. 2022-07-16, the turbidity sensor was replaced with the one that was previously being used at Archery. Between 2022-07-18 and 2022-07-21, the sensor stopped working. Back-up turbidity seemed to also not be working properly. Sonde swapped with sensor from Rist 2022-08-03, but 

```{r}
raw <- map_dfr(grep(list.files("data/sensor_data/2022/legacy/", full.names = T), pattern = "hydrovu", invert = F, value = T), hydrovu_reader)

names(raw) <- make.names(names(raw), unique = T)

rawless <- raw %>% select(DT = contains('Date.Time'),
                      Water_Temp_F = as.numeric(contains('Temperature..F.')),
                      pH = contains('pH'),
                      ORP_mV = contains('ORP'),
                      #Actual_Conductivity_µS_cm = contains('Actual.Conductivity..µS.cm.'),
                      Specific_Conductivity_µS_cm = contains('Specific.Conductivity..µS.cm.'),
                      #Salinity_PSU = contains('Salinity..psu.'),
                      DO_ppm = contains('DO..ppm'),
                      Turbidity_NTU = contains('Turbidity'),
                      #TSS_mg_L = contains('Total.Suspended.Solids..mg.L.'),
                      #Chla_RFU = contains('Chl.a.Fluorescence..RFU.'),
                      #Chla_µg_L = contains('Chl.a.Concentration..µg.L.'),
                      #Pressure_PSI = contains('Pressure..psi.'),
                      Depth_ft = contains('Depth..ft')) %>%
                      #Elevation_m = contains('Level..Elevation..m.'),
                      #Depth_to_Water_ft = contains('Level..Depth.to.Water..ft.')) %>%
  mutate_at(vars(2:ncol(.)), as.numeric) %>%
  mutate(DT = as_datetime(DT, tz = "UTC")) %>%
  mutate(DT = with_tz(DT, tzone = "MST")) %>%
  arrange(DT) %>%
  mutate(DT = round_date(DT, "15 minutes")) %>%
  # remove data ranges where sensor was pulled out of field:
  filter(!(DT >= '2022-05-24 09:30:00' & DT < '2022-06-01 13:30:00'),
         !(DT > '2022-07-08 14:00:00' & DT <= '2022-07-12 10:15:00'),
         !(DT >= '2022-08-04 09:50:00' & DT <= '2022-08-25 16:15:00'),
         !(DT > '2022-09-07 07:57:00')
         ) %>%
  padr::pad(by='DT') %>%
  full_join(filter(field_notes, site=="legacy"), by='DT') %>%
  mutate(date=as_date(DT),
         hour=hour(DT))

```

# Legacy depth

We had a couple issues with "level" calibration. Here, I am "back" calibrating for them to match previous and/or post level when they were correct. Assumes river depth did not change during field visit.
```{r}
depth <- select(rawless, c(DT, Depth_ft)) %>%
  arrange(DT) %>%
  group_by(DT) %>%
  summarize(Depth_ft = mean((Depth_ft))) %>%
  ungroup() %>%
  distinct(DT,.keep_all=T) %>%
  #mutate(nu=case_when(DT >= '2022-04-06 00:00:00' & DT <= '2022-04-12 10:15:00' ~ Depth_ft + 28.528, 
  #                    DT >= '2022-07-22 11:30:00' & DT <= '2022-07-25 14:15:00'~ Depth_ft + mean(c(28.318, 28.452))))
  mutate(Depth_ft = ifelse(DT >= '2022-04-06 00:00:00' & DT <= '2022-04-12 10:15:00', Depth_ft + 28.528, Depth_ft)) %>%
  mutate(Depth_ft = ifelse(DT >= '2022-07-22 11:30:00' & DT <= '2022-07-25 14:15:00', Depth_ft + mean(c(28.318, 28.452)), Depth_ft))

ggplot(depth) +
  geom_line(aes(DT,Depth_ft))
```

## Legacy turbidity

```{r}
turbidity <- select(raw, c(DT, Turbidity_NTU, visit_comments)) %>%
  arrange(DT) %>%
  group_by(DT,visit_comments) %>%
  summarize(Turbidity_NTU = mean(as.numeric(Turbidity_NTU))) %>%
  ungroup() %>%
  distinct(DT,.keep_all=T) %>%
  mutate(Turbidity_NTU = ifelse(DT >= '2022-06-01 13:15:00' & DT <= '2022-07-16 10:15:00' & Turbidity_NTU == 0, NA, Turbidity_NTU)) %>%
  mutate(Turbidity_NTU = ifelse(Turbidity_NTU >= 3000, 3000, Turbidity_NTU)) %>%
  group_by()
  
  

ggplot() +
  geom_line(data=turbidity,aes(DT,Turbidity_NTU)) +
  geom_line(data=turb,aes(DT,Lincoln), color='red')
```


