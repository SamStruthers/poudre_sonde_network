---
title: "post_2022"
author: "Katie Willi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

library(lubridate)

library(rvest)

library(dygraphs)

library(labelled)

library(zoo)
```
 
 Listed accuracy and range for sensors:

 Temperature: ±0.1 Celsius, -5 to 50 C

 Barometric Pressure: ±1.0 mbars, 300 to 1,100 mbars

 pH: ±0.1 pH, 0 to 14 pH

 ORP: ±5 mV

 Conductivity: ±0.5% of reading plus 1 μS/ cm from 0 to 100,000 μS/cm; ±1.0% of reading from 100,000 to 200,000 μS/cm; ±2.0% of reading from 200,000 to 350,000 μS/cm

 TDS/Salinity: range of 0 to 350 ppt/0 to 350 PSU

 RDO: ±0.1 mg/L or ±2% of reading (whichever is greater)

 Turbidity: ±2% of reading or ±0.5 NTU (whichever is greater)

 TSS: range of 1 to 1,500 mg/L

 Pressure: ±0.1% FS from -5 to 50°C

 Chlorophyll-a: range of 0-100 RFU or 1-1,000 μg/L
 
#### Pulling up field notes
This is the first year that there are consistent field notes. 

```{r}
# WHEN DATA WAS STORED ON GOOGLE DRIVE:
# field_notes <- read_sheet("https://docs.google.com/spreadsheets/d/11Gc1eS1wt9NrU12hWw1mUl25ixKZrTndIVCsvD4UKao/edit#gid=0") %>%
#   mutate(start_time_mst = (substr(start_time_mst, 12, 19)),
#          DT = round_date(as_datetime(paste0(date,' ',start_time_mst), tz="MST"), '15 mins'))

# NOW, ON MICROSOFT ONEDRIVE:

field_notes <- readxl::read_excel('data/sensor_field_notes.xlsx') %>%
  mutate(DT = (paste0(date, " ", start_time_mst))) %>%
  mutate(DT = ymd_hm(DT)) %>%
  arrange(DT) %>%
  mutate(DT = round_date(DT, "15 minutes")) %>%
  filter(year(DT)>2021)
```

#### Downloading calibration reports. 

These are a bit tricky to automate nicely because the calibration table structure is different depending on what sensors are on the sonde, and what ports they're in...

```{r}
# setwd("C:/Users/katie/Documents/0_My_Git/poudre_sonde_network/data/cal_reports")
# 
# #folder <- drive_get(as_id('https://drive.google.com/drive/folders/1XZwrnSaqd7o9GzfaYxdXdZtpZ_vEyixF'))
# 
# cal_files <- drive_ls(folder, type = "html")
# 
# walk(cal_files$id, ~ drive_download(as_id(.x)))

cal_files <- list.files("data/calibration_reports", pattern=".html")

cal_table <- vector("list", length = length(cal_files)) 

for(i in 1:length(cal_table)){

cal <- rvest::read_html(paste0("data/calibration_reports/", cal_files[i])) %>%
  rvest::html_nodes('div') %>%
  rvest::html_text() %>%
  as_tibble()

rdo <- cal %>% filter(grepl("RDO", value)) %>% pull() %>% str_replace_all(., " ", "")

ph_orp <- cal %>% filter(grepl("pH/ORP", value)) %>% pull() %>% str_replace_all(., " ", "")

conductivity <- cal %>% filter(grepl("Conductivity",value)) %>% pull() %>% str_replace_all(., " ", "")

turbidity <- cal %>% filter(grepl("Turbidity",value)) %>% pull() %>% str_replace_all(., " ", "")

time_mst <- paste0(str_sub(cal_files[i], -13, -12),":", str_sub(cal_files[i], -11, -10))

date <- paste0(str_sub(cal_files[i], -22, -19),"-", str_sub(cal_files[i], -18, -17),"-", str_sub(cal_files[i], -16, -15))

cal_table[[i]] <- tibble(site = sub("\\_.*", "", cal_files[i]),
                     
                     DT = ymd_hm(paste0(date, " ", time_mst)),
                     
                     #Dissolved Oxygen
                     rdo_slope = str_match(rdo, "Slope\\s*(.*?)\\s*Offset")[,2],
                     rdo_offset = str_match(rdo, "Offset\\s*(.*?)\\s*mg/L")[,2],
                     rdo_100 = str_match(rdo, "PreMeasurement\\s*(.*?)\\s*%SatPost")[,2],
                     rdo_conc = str_match(rdo, "Concentration\\s*(.*?)\\s*mg/LPreMeasurement")[,2],
                     rdo_temp = str_match(rdo, "Temperature\\s*(.*?)\\s*°C")[,2],
                     rdo_pressure = str_match(rdo, "Pressure\\s*(.*?)\\s*mbar")[,2],
                     
                     #pH
                     ph_slope_pre = str_match(ph_orp, "Offset1Slope\\s*(.*?)\\s*mV/pH")[,2],
                     ph_offset_pre = str_match(ph_orp, "mV/pHOffset\\s*(.*?)\\s*mVSlopeandOffset2")[,2],
                     ph_slope_post = str_match(ph_orp, "Offset2Slope\\s*(.*?)\\s*mV/pH")[,2],
                     ph_offset_post = str_match(ph_orp, paste0(ph_slope_post,"mV/pHOffset\\s*(.*?)\\s*mVORPORP"))[,2],
                     ph_7_nice = str_sub(str_match(ph_orp, "PostMeasurementpH7\\s*(.*?)\\s*mVCal")[,2], 10, nchar(str_match(ph_orp, "PostMeasurementpH7\\s*(.*?)\\s*mVCal")[,2])),
                     ph_7_other = str_sub(str_match(ph_orp, "PostMeasurementpH6\\s*(.*?)\\s*mVCal")[,2], 10, nchar(str_match(ph_orp, "PostMeasurementpH6\\s*(.*?)\\s*mVCal")[,2])),
                     ph_7 = ifelse(is.na(ph_7_nice), ph_7_other, ph_7_nice),
                     
                     #ORP
                     orp_offset = ifelse(is.na(str_match(ph_orp, "Zobell'sOffset\\s*(.*?)\\s*mVTemperature")[,2]),
                            str_match(ph_orp, "ZoBell'sOffset\\s*(.*?)\\s*mVTemperature")[,2],
                            str_match(ph_orp, "Zobell'sOffset\\s*(.*?)\\s*mVTemperature")[,2]),
                     
                     #Conductivity
                     tds_conversion_ppm=str_sub(str_match(conductivity, "TDSConversionFactor\\s*(.*?)\\s*CellConstant")[,2], 6, nchar(str_match(conductivity, "TDSConversionFactor\\s*(.*?)\\s*CellConstant")[,2])),
                     cond_cell_constant=str_match(conductivity, "CellConstant\\s*(.*?)\\s*ReferenceTemperature")[,2],
                     cond_pre=str_match(conductivity,paste0(str_match(conductivity,
                        "PreMeasurementActual\\s*(.*?)\\s*SpecificConductivity")[,2],"SpecificConductivity\\s*(.*?)\\s*µS/cmPost"))[,2],
                     cond_post=str_match(conductivity,paste0(str_match(conductivity,
                        "PostMeasurementActual\\s*(.*?)\\s*SpecificConductivity")[,2],"SpecificConductivity\\s*(.*?)\\s*µS/cm"))[,2],
                     
                     #Turbidity
                     ntu_slope=str_match(turbidity, "Slope\\s*(.*?)\\s*Offset")[,2],
                     ntu_offset=str_match(turbidity, "Offset\\s*(.*?)\\s*NTU")[,2],
                     ntu_10=str_match(turbidity, "CalibrationPoint1PreMeasurement\\s*(.*?)\\s*NTUPost")[,2],
                     ntu_100=str_match(turbidity, "CalibrationPoint2PreMeasurement\\s*(.*?)\\s*NTUPost")[,2],
                     
                     #Factory Defaults
                     factory_defaults= paste0(ifelse(is.na(ntu_slope), "Turbidity ", ""),
                                  ifelse(is.na(rdo_slope), "RDO ", ""),
                                  ifelse(is.na(ph_slope_post), "pH ", ""),
                                  ifelse(is.na(orp_offset), "ORP ", ""),
                                  ifelse(is.na(cond_post), "Conductivity ", ""))) %>%
  select(-c(ph_7_nice, ph_7_other))
}

cal_table <- bind_rows(cal_table) %>%
  distinct(.keep_all = TRUE) %>%
  group_by(site) %>%
  mutate(DT = round_date(DT, "15 minutes")) %>%
  padr::pad(by='DT', group = 'site')
  # set_variable_labels("site" = "Sensor Site",     
  #                     "DT" = "Date Time (MST)",       
  #                     "rdo_slope"  = "RDO Post-Calibration Slope, Unitless", 
  #                     "rdo_offset" = "RDO Post-Calibration Offset (mg/L)",   
  #                     "rdo_100"  = "RDO Pre-Calibration at 100% (% Saturation)",    
  #                     "rdo_conc"  = "RDO 100% Saturation Concentration @ Calibration (mg/L)",   
  #                     "rdo_temp" = "RDO Temperature @ Calibration (deg Celsius)",     
  #                     "rdo_pressure" = "RDO Barometric Pressure @ Calibration (mbar)",   
  #                     "ph_slope_pre" = "pH Pre-Calibration Slope (mV/pH)",
  #                     "ph_offset_pre" = "pH Pre-Calibration Offset (mV)",
  #                     "ph_slope_post" = "pH Post-Calibration Slope (mV/pH)",
  #                     "ph_offset_post" = "pH Post-Calibration Offset (mV)",
  #                     "ph_7" = "pH 7 Post-Calibration Reading (mV)",      
  #                     "orp_offset" = "ORP Post-Calibration Offset at ZoBell's (mV)",    
  #                     "tds_conversion_ppm" = "TDS Post-Calibration Conversion Factor (ppm)",
  #                     "cond_cell_constant" = "Conductivity Cell Constant Post-Calibration, Unitless",
  #                     "cond_pre" = "Specific Conductivity Pre-Calibration (µS/cm)",   
  #                     "cond_post" = "Specific Conductivity Post-Calibration (µS/cm)",     
  #                     "ntu_slope" = "Turbidity Post-Calibration Slope, Unitless",    
  #                     "ntu_offset" = "Turbidity Post-Calibration Offset (NTU)",      
  #                     "ntu_10" = "Turbidity Pre-Calibration @ 10 NTU (NTU)",      
  #                     "ntu_100" = "Turbidity Pre-Calibration @ 100 NTU (NTU)",    
  #                     "factory_defaults" = "Sensors re-set to factory defaults")
```

#### Downloading sonde data

Html reader functions
```{r}
# from HydroVu, on the cloud:
hydrovu_reader <- function(file) {
    
    raw_data <- rvest::read_html(file) %>%
      rvest::html_node('table') %>%
      rvest::html_table() %>%
      slice(-1:-8) %>%
      janitor::row_to_names(row_number = 1) 
}

# from AquaTROLL 500/600, in the field:
troll_reader <- function(file) {
  
  raw_data <- rvest::read_html(file) %>%
    rvest::html_node('table') %>%
    rvest::html_table() %>%
    slice(-1:-25) %>%
    janitor::row_to_names(row_number = 1) 
}

# from VuLink, in the field:
vulink_reader <- function(file) {
  
  raw_data <- rvest::read_html(file) %>%
    rvest::html_node('table') %>%
    rvest::html_table() %>%
    slice(-1:-31) %>%
    janitor::row_to_names(row_number = 1) 
}

# data from the VuLink itself, including temperature, baro, and power
tube_reader <- function(file) {
    
    raw_data <- rvest::read_html(file) %>%
      rvest::html_node('table') %>%
      rvest::html_table() %>%
      slice(-1:-8) %>%
      janitor::row_to_names(row_number = 1) 
}
```

# Downloading relevant outside datasets

```{r}
usgs_lincoln <- dataRetrieval::readNWISuv("06752260", parameterCd = "00065", startDate = "2022-04-01", endDate = "2022-12-01") %>%
  mutate(DT=ymd_hms(dateTime))%>%
  #mutate(date = as_date(dateTime)) %>%
  #group_by(date) %>%
  #summarize(X_00065_00000 = mean(X_00065_00000)) %>%
  mutate(Depth_m = X_00065_00000 * 0.3048) %>%
  select(DT, 
         Depth_m) %>%
  mutate(site="usgs_lincoln")
```




# Legacy

So far in 2022, all data has been sent to HydroVu (outside of genomic sampling date 2022-09-19). This location encountered several issues this field season: sensor pulled 2022-05-24 due to fears that its infrastructure would wash away. Sensor was re-deployed 2022-06-01, but was then pulled out due to tech issues 2022-07-08 and turbidity problems. Sometime between then and 2022-07-12, turbidity sensor totally broke. 2022-07-16, the turbidity sensor was replaced with the one that was previously being used at Archery. Between 2022-07-18 and 2022-07-21, the back-up sensor stopped working. After this we we swapped the sonde with sensor from Rist 2022-08-03. On 2022-08-04, the sensor was pulled because flows were too low (sensor was likely not suspended in the water 8/3 - 8/4). Redeployed on 2022-08-25, though issues with turbidity and ORP occurred from then until

```{r}
# No VuLink connection during final genomic survey (water was too low for full deployment)
raw_troll_legacy <- map_dfr(grep(list.files("data/sensor_data/2022/legacy/", full.names = T), pattern = "trolled", invert = F, value = T), troll_reader)
names(raw_troll_legacy) <- make.names(names(raw_troll_legacy), unique = T)

rawless_troll_legacy <- raw_troll_legacy %>% select(DT = contains('Date.Time'),
                      Water_Temp_C = as.numeric(contains('Temperature...C')),
                      pH = contains('pH'),
                      ORP_mV = contains('ORP'),
                      #Actual_Conductivity_µS_cm = contains('Actual.Conductivity..µS.cm.'),
                      Specific_Conductivity_µS_cm = contains('Specific.Conductivity..µS.cm.'),
                      #Salinity_PSU = contains('Salinity..psu.'),
                      #DO_ppm = contains('DO..ppm'),
                      Turbidity_NTU = contains('Turbidity'),
                      #TSS_mg_L = contains('Total.Suspended.Solids..mg.L.'),
                      #Chla_RFU = contains('Chl.a.Fluorescence..RFU.'),
                      #Chla_µg_L = contains('Chl.a.Concentration..µg.L.'),
                      #Pressure_PSI = contains('Pressure..psi.'),
                      Depth_m = contains('Depth')) %>%
  mutate(Depth_m=as.numeric(Depth_m)* 0.3048) %>% # logged in feet >:(
  mutate(DT = ymd_hms(DT)) %>%
  mutate(DT = DT - lubridate::hours(1)) %>% # reported in MDT >:(
  mutate(DT = as.character(round_date(ymd_hms(DT), "15 minutes"))) %>%
  mutate(DT = ymd_hms(DT))

# Downloading VuLink data:
raw_tube_legacy <- map_dfr(grep(list.files("data/sensor_data/2022/legacy/", full.names = T), pattern = "VuLink", invert = F, value = T, ignore.case = F), tube_reader) %>%
  rename(DT=1,
         PVC_Temp=2,
         Battery=3,
         Air_Baro=4) %>%
  mutate(DT = ymd_hms(DT)) %>%
  mutate(DT = DT - lubridate::hours(7)) %>%
  mutate(DT = as.character(round_date(ymd_hms(DT), "15 minutes"))) %>%
  mutate(DT = ymd_hms(DT))  %>%
  mutate_at(vars(2:ncol(.)), as.numeric)

raw_legacy <- map_dfr(grep(list.files("data/sensor_data/2022/legacy/", full.names = T), pattern = "TROLL", invert = F, value = T, ignore.case = F), hydrovu_reader)
names(raw_legacy) <- make.names(names(raw_legacy), unique = T)

rawless_legacy <- raw_legacy %>% select(DT = contains('Date.Time'),
                      Water_Temp_C = as.numeric(contains('Temperature..C')),
                      pH = contains('pH'),
                      ORP_mV = contains('ORP'),
                      #Actual_Conductivity_µS_cm = contains('Actual.Conductivity..µS.cm.'),
                      Specific_Conductivity_µS_cm = contains('Specific.Conductivity..µS.cm.'),
                      #Salinity_PSU = contains('Salinity..psu.'),
                      #DO_ppm = contains('DO..mg.L'),
                      Turbidity_NTU = contains('Turbidity'),
                      #TSS_mg_L = contains('Total.Suspended.Solids..mg.L.'),
                      #Chla_RFU = contains('Chl.a.Fluorescence..RFU.'),
                      #Chla_µg_L = contains('Chl.a.Concentration..µg.L.'),
                      #Pressure_PSI = contains('Pressure..psi.'),
                      Depth_m = contains('Depth..m')) %>%
  mutate(DT = ymd_hms(DT)) %>%
  mutate(DT = DT - lubridate::hours(7)) %>%
  rbind(rawless_troll_legacy) %>%
  mutate_at(vars(2:ncol(.)), as.numeric) %>%
  mutate(site="legacy") %>%
  arrange(ymd_hms(DT)) %>%
  mutate(DT = as.character(round_date(ymd_hms(DT), "15 minutes"))) %>%
  mutate(DT = ymd_hms(DT)) %>%
  full_join(raw_tube_legacy, by='DT') %>%
  full_join(filter(field_notes, site=="legacy"), by=c('DT','site')) %>%
  mutate(date=as_date((DT)),
         hour=hour(DT)) %>%
  arrange(ymd_hms(DT)) %>%
   # remove data ranges where sensor was pulled out of field.
  dplyr::filter(ymd_hms(DT) >= ymd_hms('2022-04-06 17:30:00'),
         !(ymd_hms(DT) >= ymd_hms('2022-05-24 09:30:00') & ymd_hms(DT) < ymd_hms('2022-06-01 13:30:00')),
         !(ymd_hms(DT) > ymd_hms('2022-07-08 14:00:00') & ymd_hms(DT) <= ymd_hms('2022-07-12 10:00:00')),
         !(ymd_hms(DT) >= ymd_hms('2022-08-04 09:50:00') & ymd_hms(DT) <= ymd_hms('2022-08-25 16:15:00')),
         !(ymd_hms(DT) > ymd_hms('2022-09-07 06:57:00') & ymd_hms(DT) <= ymd_hms('2022-09-19 07:00:00'))
         ) %>%
  mutate(DT = ymd_hms(DT)) %>%
  padr::pad(by='DT') %>%
  full_join(na.locf(na.locf(filter(cal_table, site=="legacy")),fromLast=TRUE), by=c('site','DT'))
```

## Legacy temperature

```{r}
legacy_temp <- dplyr::select(rawless_legacy, c(DT, Water_Temp_C, PVC_Temp, site)) %>%
  arrange(ymd_hms(DT)) %>%
  group_by(site,DT) %>%
  summarize(Water_Temp_C = mean(Water_Temp_C),
            PVC_Temp = mean(PVC_Temp)) %>%
  ungroup() %>%
  distinct(DT,.keep_all=T) %>%
  mutate(pre = lag(Water_Temp_C, 1),
         post = lead(Water_Temp_C, 1),
         roll = (pre+Water_Temp_C+post)/3)

compare <- legacy_temp %>%
  select(DT, Water_Temp_C, PVC_T, site) %>%
  #rbind(usgs_lincoln) %>%
  pivot_wider(., values_from = Water_Temp_C, names_from = "site") %>%
  dplyr::filter(DT >= ymd_hms('2022-04-06 17:30:00'))

timeseries <- xts::xts(compare, order.by = ymd_hms(compare$DT))

dygraph(timeseries, main="Water Temperature Timeseries (UTC)") %>% 
 dyRangeSelector() #%>%
 # dyHighlight(highlightCircleSize = 4,
 #           highlightSeriesBackgroundAlpha = 0.5,
 #            hideOnMouseOut = T) %>%
 # dyLegend(show = "follow")
```


## Legacy depth

We had a couple issues with "level" calibration. Here, I am "back-calibrating" for them to match previous and/or post level when they were correct. Assumes (though subjectively verified in field) that river depth did not change during the field visit.
```{r}
legacy_depth <- dplyr::select(rawless_legacy, c(DT, Depth_m, site)) %>%
  arrange(ymd_hms(DT)) %>%
  group_by(site,DT) %>%
  summarize(Depth_m = mean((Depth_m))) %>%
  ungroup() %>%
  distinct(DT,.keep_all=T) #%>%

legacy_depth <- legacy_depth %>%
  mutate(Depth_m_p1 = ifelse(DT >= ymd_hms('2022-04-06 06:00:00') & DT < ymd_hms('2022-04-12 09:30:00'), Depth_m + abs(filter(legacy_depth, DT == ymd_hms('2022-04-12 09:15:00'))$Depth_m - filter(legacy_depth, DT == ymd_hms('2022-04-12 09:30:00'))$Depth_m), Depth_m)) %>%
  mutate(Depth_m_p1 = ifelse(DT >= ymd_hms('2022-07-22 11:30:00') & DT <= ymd_hms('2022-07-25 14:15:00'), Depth_m_p1 + abs(filter(legacy_depth, DT == ymd_hms('2022-07-22 11:15:00'))$Depth_m_p1 - filter(legacy_depth, DT == ymd_hms('2022-07-22 11:30:00'))$Depth_m_p1), Depth_m_p1)) %>%
  mutate(pre = lag(Depth_m_p1, 1),
         post = lead(Depth_m_p1, 1),
         roll = (pre+Depth_m_p1+post)/3)

compare <- legacy_depth %>%
  select(DT, Depth_m=Depth_m_p1, site) %>%
  rbind(usgs_lincoln) %>%
  pivot_wider(., values_from = Depth_m, names_from = "site") %>%
  dplyr::filter(DT >= ymd_hms('2022-04-06 17:30:00'))

timeseries <- xts::xts(compare, order.by = ymd_hms(compare$DT))

dygraph(timeseries, main="Depth Timeseries (UTC)") %>% 
 dyRangeSelector()
```

## Legacy conductivity
```{r}
legacy_conductivity <- dplyr::select(rawless_legacy, c(DT, Specific_Conductivity_µS_cm, site)) %>%
  arrange(ymd_hms(DT)) %>%
  group_by(site,DT) %>%
  summarize(Specific_Conductivity_µS_cm = mean((Specific_Conductivity_µS_cm))) %>%
  ungroup() %>%
  distinct(DT,.keep_all=T) %>%
  mutate(pre = lag(Specific_Conductivity_µS_cm, 1),
         post = lead(Specific_Conductivity_µS_cm, 1),
         roll = (pre+Specific_Conductivity_µS_cm+post)/3)

compare <- legacy_conductivity %>%
  select(DT, Specific_Conductivity_µS_cm, site) %>%
  #rbind(usgs_lincoln) %>%
  pivot_wider(., values_from = Specific_Conductivity_µS_cm, names_from = "site") %>%
  dplyr::filter(DT >= ymd_hms('2022-04-06 17:30:00'))

timeseries <- xts::xts(compare, order.by = ymd_hms(compare$DT))

dygraph(timeseries, main="SpC Timeseries (UTC)") %>% 
 dyRangeSelector() #%>%
 # dyHighlight(highlightCircleSize = 4,
 #           highlightSeriesBackgroundAlpha = 0.5,
 #            hideOnMouseOut = T) %>%
 # dyLegend(show = "follow")
```




## Legacy turbidity

```{r}
turbidity <- select(rawless, c(DT, Specific_Conductivity_µS_cm, Turbidity_NTU, visit_comments, ntu_offset,ntu_slope,ntu_10,ntu_100,factory_defaults)) %>%
  arrange(DT) %>%
  group_by(DT, visit_comments, ntu_offset,ntu_slope,ntu_10,ntu_100,factory_defaults) %>%
  summarize(Turbidity_NTU = mean(as.numeric(Turbidity_NTU)),
            Spec_Check = mean(as.numeric(Specific_Conductivity_µS_cm))) %>%
  ungroup() %>%
  distinct(DT,.keep_all=T) %>%
  mutate(raw_turb = (Turbidity_NTU-as.numeric(ntu_offset))/as.numeric(ntu_slope))

  mutate(Turbidity_NTU = ifelse(DT >= ymd_hms('2022-06-01 13:15:00') & DT <= ymd_hms('2022-07-16 10:15:00') & Turbidity_NTU == 0, NA, Turbidity_NTU)) %>%
  mutate(Turbidity_NTU = ifelse(Turbidity_NTU >= 3000, 3000, Turbidity_NTU)) %>%
  group_by()
  
  
# looking at 
ggplot() +
  geom_line(data=turbidity,aes(DT,Turbidity_NTU)) +
  geom_line(data=depth,aes(DT,Depth_m*500), color='red')
```

# Timberline

This season, all sonde data was sent to HydroVu. 

```{r}
raw <- map_dfr(grep(list.files("data/sensor_data/2022/timberline/", full.names = T), pattern = "HydroVu", invert = F, value = T), hydrovu_reader)

names(raw) <- make.names(names(raw), unique = T)

rawless_timber <- raw %>% select(DT = contains('Date.Time'),
                      Water_Temp_C = as.numeric(contains('Temperature..C')),
                      pH = contains('pH'),
                      ORP_mV = contains('ORP'),
                      #Actual_Conductivity_µS_cm = contains('Actual.Conductivity..µS.cm.'),
                      Specific_Conductivity_µS_cm = contains('Specific.Conductivity..µS.cm.'),
                      #Salinity_PSU = contains('Salinity..psu.'),
                      DO_ppm = contains('DO..ppm'),
                      Turbidity_NTU = contains('Turbidity'),
                      #TSS_mg_L = contains('Total.Suspended.Solids..mg.L.'),
                      #Chla_RFU = contains('Chl.a.Fluorescence..RFU.'),
                      #Chla_µg_L = contains('Chl.a.Concentration..µg.L.'),
                      #Pressure_PSI = contains('Pressure..psi.'),
                      Depth_m = contains('Depth..m')) %>%
                      #Elevation_m = contains('Level..Elevation..m.'),
                      #Depth_to_Water_ft = contains('Level..Depth.to.Water..ft.')) %>%
  mutate(DT = ymd_hms(DT)) %>%
  mutate(DT = DT - lubridate::hours(7)) %>%
  #rbind(rawless_troll) %>%
  mutate_at(vars(2:ncol(.)), as.numeric) %>%
  arrange(ymd_hms(DT)) %>%
  mutate(DT = as.character(round_date(ymd_hms(DT), "15 minutes"))) %>%
  # remove data ranges where sensor was pulled out of field.
  dplyr::filter(ymd_hms(DT) >= ymd_hms('2022-04-06 08:15:00')) %>%
  mutate(DT = ymd_hms(DT)) %>%
  padr::pad(by='DT') %>%
  full_join(filter(field_notes, site=="timberline"), by='DT') %>%
  mutate(date=as_date((DT)),
         hour=hour(DT)) %>%
  arrange(ymd_hms(DT)) %>%
  mutate(site="timberline") %>%
  full_join(na.locf(na.locf(filter(cal_table, site=="timberline")),fromLast=TRUE), by=c('site','DT'))
```
# Timbrline depth

We had a couple issues with "level" calibration. Here, I am "back-calibrating" for them to match previous and/or post level when they were correct. Assumes (though subjectively verified in field) that river depth did not change during field visit. Moreover, we had to change the depth of the sonde several times due to root growth in the bank, as well as massive sediment dumps at this station. 
```{r}
depth <- dplyr::select(rawless_timber, c(DT, Depth_m, site)) %>%
  arrange(ymd_hms(DT)) %>%
  group_by(site,DT) %>%
  summarize(Depth_m = mean((Depth_m))) %>%
  ungroup() %>%
  distinct(DT,.keep_all=T) %>%
  mutate(Depth_m_p1 = ifelse(DT >= ymd_hms('2022-04-06 08:00:00') & DT < ymd_hms('2022-04-07 17:15:00'), 
                          Depth_m + abs(
                            filter(depth, DT == ymd_hms('2022-04-07 16:15:00'))$Depth_m - 
                            filter(depth, DT == ymd_hms('2022-04-07 17:15:00'))$Depth_m
                            ), 
                          Depth_m)) %>%
  mutate(Depth_m_p1 = ifelse(DT > '2022-09-14 13:15:00', 
                          Depth_m_p1 + abs(
                            filter(depth, DT == ymd_hms('2022-09-14 13:00:00'))$Depth_m_p1 -
                            filter(depth, DT == ymd_hms('2022-09-14 13:30:00'))$Depth_m_p1
                            ), 
                          Depth_m)) %>%
  mutate(pre = lag(Depth_m_p1, 1),
         post = lead(Depth_m_p1, 1),
         roll = (pre+Depth_m_p1+post)/3)

compare <- depth %>%
  select(DT, Depth_m=Depth_m_p1, site) %>%
  rbind(usgs_lincoln) %>%
  pivot_wider(., values_from = Depth_m, names_from = "site") %>%
  dplyr::filter(DT >= ymd_hms('2022-04-06 08:00:00'))

timeseries <- xts::xts(compare, order.by = ymd_hms(compare$DT))

dygraph(timeseries, main="Depth Timeseries (UTC)") %>% 
 dyRangeSelector() #%>%
 # dyHighlight(highlightCircleSize = 4,
 #           highlightSeriesBackgroundAlpha = 0.5,
 #            hideOnMouseOut = T) %>%
 # dyLegend(show = "follow")
```
