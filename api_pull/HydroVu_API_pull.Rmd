---
title: "HydroVu API Pull"
author: "B Steele"
date: "`r Sys.Date()`"
output: html_document
---

# Purpose

This R-markdown accesses the HydroVu server via the API to download data within this scripted workflow. See the README.md file for directions to set up the credentials.yml file sourced in this script.

## Requirements

This Markdown requires the package 'HydroVuR', which is currently forked in B's GH.

## Workspace Set Up

For grabbing data from HydroVu, we'll be using the credentials.yml file and the package 'HydroVuR', which is available on GitHub through devtools.

```{r}
devtools::install_github("steeleb/HydroVuR")
library('tidyverse')
library('HydroVuR')
source('hv_getdata_id.R')
source('hv_locations_all.R')
```

And point to the directory where the data should be saved to:

```{r}
dump_dir = '~/OneDrive - Colostate/poudre_sonde_network/data/api_dump/'
```

## Accessing the API

First thing, we're going to read in our client id and client secret for accessing the HydroVu API. Don't print these out in this chunk: if you save your Rmd file with the chunk history, that's another way that the world can see your data. :)

```{r}
creds = yaml::read_yaml('credentials.yml')

client_id = as.character(creds['client'])
client_secret = as.character(creds['secret'])

# get a token for location lists and data access
token <- hv_auth(client_id, client_secret)
```

Get location list - this will list ALL locations that have ever existed in HydroVu:

```{r}
locs <- hv_locations_all(token)
#make a list of site names
options(scipen = 999)
loc_list <- locs$id

```

Get data for each location. Note this maps over the entire list of locations, many of which are unlikely to be active during the time you specify. Don't freak out if you see a bunch of '404 Not Found' errors, you're just seeing the list of locations that are not active. The data frame 'alldata' should contain your data from all applicable sites during the timeframe indicated. Note that this will take some time (one month of data for 5 sites takes \~10 mins. Be patient!

```{r}
# add date range you are interested in; data are stored in HydroVu in UTC
startdate = '2022-08-01 00:00:00'
enddate = '2022-09-01 00:00:00'
timezone = 'UTC'

#map over the location ids 
alldata <- map(loc_list, 
                   hv_data_id, 
                   start_time = startdate, 
                   end_time = enddate, 
                   token = token, 
                   tz = timezone)

#grab only locations with data (stored as a data frame) / drop 404 errors
filtered <- purrr::keep(alldata, is.data.frame)

#bind lists together (now that all are dataframes, we can just collate quickly)
one_df <- bind_rows(filtered) %>% 
  rename(id = Location,
         parameter = Parameter,
         units = Units) %>% 
  left_join(., locs) %>% 
  select(id, name, timestamp, parameter, value, units)
```

## Save your data

```{r}
write.csv(one_df, file.path(dump_dir, '2022-08_apipull.csv'), row.names = F)
```
