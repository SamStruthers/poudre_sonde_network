---
title: "Preparatory Workflow"
author: "ROSSyndicate"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 90
---

*This workflow is where our site-parameter thresholds are developed for use in our
automated quality assurance/quality control (QA/QC) pipeline. To create these thresholds,
we first pull in all raw data, remove the known instances of sensor malfunction, then
perform statistical analyses on the "good" data to develop hydrologic seasonal
thresholds.*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = 'hide', error = FALSE, message = 'hide')
```

```{r}
# Load necessary packages:
source("src/package_loader.R")
lapply(c("data.table", "tidyverse", "rvest", "readxl", "lubridate", "zoo", "padr","plotly", "feather", "RcppRoll", "yaml", "ggpubr", "profvis", "janitor"), package_loader)

walk(list.files('src/qaqc/download_and_flag_fxns', pattern = "*.R", full.names = TRUE, recursive = TRUE), source)

#walk(list.files('src/mWater_collate/', pattern = "*.R", full.names = TRUE, recursive = TRUE), source)
```

## *Step 1: Import and collate data*

*Load field notes and define the start time as the 15 minutes preceding the recorded field
time*

```{r}
old_field_notes <- readxl::read_excel('data/sensor_field_notes.xlsx') %>%
  clean_field_notes()

new_field_notes <- grab_mWater_sensor_notes()

#merge new mwater notes (sensor_notes) and old notes (field notes)  
all_field_notes <- rbind(old_field_notes, new_field_notes)

sensor_malfunction_notes <- grab_mWater_sensor_malfunctions()
```

*Merge the data sets from all API pulls. Then for developing this workflow, subset the
data to only the 2022 and 2023 field season. (Previous field seasons were managed quite
differently, and therefore should be treated differently.)*

```{r}
all_data <- munge_api_data(api_path = "data/api/krw_everything_backup2.0_mdt_dl/") %>%
  dplyr::filter(lubridate::year(DT_round) >= 2022) 
```

*Lastly, we save this data set for posterity.*

```{r}
# This will be a parquet file in the future?
#write_feather(all_data, paste0('data/SOME_FOLDER_FOR_POSTERITY/collated_raw_sonde_v', Sys.Date(), '.feather'))
```

## *Step 2: Develop site-parameter data thresholds*

*Here, we split up all of our site-parameter combinations into a list that we can more
easily iterate over. Then, across those lists, we average any observations whose frequency
is greater than 15 minutes so that our data set is consistently recorded at 15-minute
intervals. We also preserve the total number of observations within the 15-minute
increment used to calculate the mean, as well as the spread (max-min). After these
calculations, we use {padr}'s `pad()` function to fill in data gaps at this 15-minute
interval. Lastly, we join these data frames with the field notes.*

```{r}
# format and summarize data
# Determine each site and parameter in all_data 
sites <- unique(all_data$site)
params <- c("Battery Level",
            "Baro",
            "Chl-a Fluorescence", 
            "Depth", 
            "DO", 
            "External Voltage", 
            "ORP", 
            "pH",
            "Specific Conductivity",
            "Temperature",
            "Turbidity")

# Constructing a df to iterate over each site-parameter combination
site_param_combos <- tidyr::crossing(sites, params)

# Make a list of the summarized data
all_data_summary_list <- purrr::map2(.x = site_param_combos$sites, 
                                     .y = site_param_combos$params, 
                                     ~summarize_site_param_full(site_arg = .x,
                                                                parameter_arg = .y,
                                                                api_data = all_data,
                                                                notes = all_field_notes)) %>% 
  # set the names for the dfs in the list
  purrr::set_names(paste0(site_param_combos$sites, "-", site_param_combos$params)) %>% 
  # remove NULL values from the list
  purrr::keep(~ !is.null(.))

# Bind rows for each df in list
all_data_summary_df <- dplyr::bind_rows(all_data_summary_list)
```

#### *Add summary stats*

*Here, we are adding in contextual summary statistics that can be used to describe a given
observation's relationship to its neighboring observations. This includes:*

-   *the previous and next observation and their slopes*
-   *the 7-point (each observation and the previous 6) moving median, mean, slope, and
    standard deviation*
-   *the hydrologic "season" in which the observation lands in: Winter base flow: Dec,
    Jan, Feb, Mar, Apr Snow melt: May, Jun Monsoon: Jul, Aug, Sep Fall base flow: Oct,
    Nov*

```{r}
all_data_summary_stats_list <- all_data_summary_list %>%
  # modified generate_summary_statistics (for performing across "full" dataset)
  purrr::map(~ generate_summary_statistics_full(.))
```

#### *Define thresholds*

*Next, we create a look-up table for site-parameter thresholds to use in flagging strange
data. These thresholds are based on data from the 2022 and 2023 field season. In future
seasons, this data will be fixed (i.e., unchanging).*

```{r}
# this does not need to be a yaml solution
# add this to the threshold look up table and then save the threshold look up table 
sensor_spec_ranges <- yaml::read_yaml("src/qaqc/sensor_spec_thresholds.yml")

threshold_lookup <- all_data_summary_stats_list %>%
  purrr::map(~ make_threshold_table(.)) %>%
  dplyr::bind_rows()

readr::write_csv(threshold_lookup, 'src/qaqc/seasonal_thresholds.csv')

# save the threshold lookup table as a RDS 
# saveRDS(threshold_lookup, 'data/summary_stats/threshold_lookup.RDS')

# saveRDS(all_data_summary_stats_list, 'data/summary_stats/all_data_summary_stats_list.RDS')
```

*Compare seasonal thresholds to our own "reasonable" ranges for parameters generally:*

```{r}
realistic <- readr::read_csv('src/qaqc/realistic_thresholds.csv')

# which of our seasonal thresholds are less restrictive than what we have qualitatively deemed "reasonable"?
compare <- dplyr::left_join(threshold_lookup, realistic, by = "parameter") %>%
  dplyr::ungroup() %>%
  dplyr::filter(min > t_mean01 | max < t_mean99)

# ... not many, which is a good sign. All but ONE are conductivity
```

#### *Test thresholds to flag all data*

*Add flagging functions for each df in all_data_summary_list*

*Pass the dfs in all_data_summary_stats_list through the flagging functions:*

```{r}
# make sure that data that has already been flagged is not flagged again, except for the large anomaly flag
# ifelse(historical_data == FALSE, {add_flag}, {do nothing})

all_data_flagged <- purrr::map(all_data_summary_stats_list, function(data) {
  data %>%
    add_field_flag() %>%
    add_spec_flag() %>%
    add_realistic_flag() %>%
    add_seasonal_flag() %>%
    add_na_flag() %>%
    add_repeat_flag() %>%
    # modified add_suspect_flag (for performing across "full" dataset)
    add_suspect_flag_full() %>%
    add_malfunction_flag()
})

intrasensor_checks <- all_data_flagged %>%
  dplyr::bind_rows() %>%
  split(f = .$site) %>%
  purrr::map(~add_biofilm_flag(.)) %>%
  purrr::map(~add_frozen_flag(.)) %>%
  dplyr::bind_rows() %>%
  split(f = list(.$site, .$parameter)) 
  

final_flag <- all_data_flagged %>%
  map(~network_check(.))

# saveRDS(final_flag, 'data/flagged/all_data_flagged_complete.RDS')

# write_feather(final_flag %>% bind_rows(), 'data/flagged/all_data_flagged_complete.feather')
```

## *How well do these flags work?*

*To test how well our flags are working, we can compare the flagged data against our list
of known sensor malfunctions.*

```{r}
test <- final_flag %>%
  purrr::map(~ dplyr::mutate(., 
                             wo_sens_mal = str_remove_all(cleaner_flag, "sensor malfunction"),
                             # create column identifying obs we KNOW are bad:
                             known = ifelse(grepl("sensor malfunction", cleaner_flag), 1, 0),
                             # create column identifying obs found to be bad with flags:
                             flagged = ifelse(is.na(cleaner_flag) |
                                                grepl("sonde not employed|missing data|site visit|sv window", wo_sens_mal), 0, 1)) %>%
               dplyr::group_by(lubridate::as_date(DT_round)) %>%
               dplyr::mutate(known = sum(known),
                                flagged = sum(flagged))
  )
```

```{r}
ggplot() +
  geom_line(data = test[["legacy-pH"]], aes(DT_round, mean)) +
  geom_point(data =  filter(test[["legacy-pH"]], !is.na(cleaner_flag)), aes(DT_round, mean), color = "red") +
    geom_point(data =  filter(test[["legacy-pH"]], grepl("sensor malfunction", cleaner_flag)), aes(DT_round, mean), color = "blue")

ggplot() +
  geom_line(data = test[["legacy-Temperature"]], aes(DT_round, mean)) +
  geom_point(data =  filter(test[["legacy-Temperature"]], !is.na(cleaner_flag)), aes(DT_round, mean), color = "red") +
    geom_point(data =  filter(test[["legacy-Temperature"]], grepl("sensor malfunction", cleaner_flag)), aes(DT_round, mean), color = "blue")

```

## *Develop a final data set for testing purposes!*

*Here, I'm splitting the final data set at the end of November to test the 3-hour pull
functionality in our {targets} pipeline:*

```{r}
subset_func <- function(df){
  
  df_sub <- df %>%
    filter(DT_round <= ymd_hms("2023-11-28 12:00:00", tz = "MST"))
  
}

subset_data <- final_flag %>%
  map(~subset_func(.)) 

saveRDS(subset_data, 'data/flagged/all_data_flagged.RDS')

write_feather(subset_data %>% bind_rows(), 'data/flagged/all_data_flagged.feather')
```
