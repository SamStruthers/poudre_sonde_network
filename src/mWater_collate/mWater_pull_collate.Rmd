---
title: "mWater_pull_collate"
author: "Sam Struthers"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

#grab site metadata
sampling_sites <- read_csv("data/water_sampling_sites.csv")
# sort for sites in upper network (ie. acronyms rather than street names)
upper_sites <- sampling_sites%>%
  filter(watershed != "CLP  Mainstem-Fort Collins")%>%
  #this is to help match with user input
  mutate(site_code = tolower(site_code))

`%nin%` = Negate(`%in%`)
```

# API Pull of mWater submitted notes

```{r}
# Grab API url from yml
# Contact Sam Struthers if you need access
creds = yaml::read_yaml("src/mWater_collate/mWater_API.yml")
api_url = as.character(creds["url"])


#read in datasheet from mWater portal API
all_notes <- read_csv(url(api_url))

rm(creds, api_url)
```

# Tidying for downstream use

This is basic tidying of data set to:

-    correct datetime from UTC to Denver time

-   correct columns where Other input is allowed (Site, visit type, photos downloaded)

-   Add rounded date time

```{r}

all_notes_cleaned <- all_notes%>%
  mutate(
    #start and end dt comes in as UTC -> to MST
        start_dt = with_tz(ymd_hms(start_dt), tz = "America/Denver"),
        end_dt = with_tz(ymd_hms(end_dt), tz = "America/Denver"),
         date = as.Date(start_dt),
         time_start = format(start_dt, "%H:%M"),
        
    # If other is chosen, make site == other response      
    site = ifelse(site == "Other (please specify)", tolower(str_replace_all(site_other, " ", "")), site),
    #correct names if it is in our upper sites (acronyms)
    site = ifelse(site %in% upper_sites$site_code, toupper(site), site),
         site_other = NULL,
         #this part does not work yet
         # (cant get rid of (please specify))
         visit_type = ifelse(str_detect(visit_type, "Other"),
                             str_replace(visit_type, "Other (please specify),", visit_type_other),
                             visit_type),
         #If other is chosen, make photos downloaded equal to response
         photos_downloaded = ifelse(photos_downloaded == "Other (please specify)", photos_downloaded_other, photos_downloaded),
         photos_downloaded_other = NULL, 
         #Rounded start date time
         DT_round = floor_date(start_dt, "15 minutes")) %>%
#arrange by most recent visit
    arrange(DT_round)
```

# Sensor Notes

These are the notes that will be added to the QAQC workflow notes Most of the code in this chunk is to get the df to match the one in the QAQC workflow It can be saved as a CSV or pulled directly into QAQC workflow

```{r}
#grab only notes where technician is interacting with sensor

sensor_notes <- all_notes_cleaned%>%
  filter(grepl("Sensor",visit_type))%>%
  select(-c(visit_type_other, chla_volume_ml, vol_filtered_blank_dup, sample_collected,do_mgl,
            cond_ms_cm, temp_c, upstream_pic, downstream_pic, clarity, filter_pic, other_pic, other_pic_descriptor))%>%
  # determining sonde employed status based on sensor_change 
  mutate(sonde_employed = case_when(is.na(sensor_change)  ~ 1,
                                    sensor_change == "Pulled" ~ 0,
                                    sensor_change %in% c("Swapped", "Deployed") ~ 1),
         #Date/field season columns to match QAQC workflow
         DT_join = as.character(DT_round),
         field_season = year(DT_round),
         last_site_visit = DT_round
  )%>%
  arrange(desc(start_dt))
         
#write to CSV
write_csv(sensor_notes, "data/mWater_sensor_field_notes.csv")

```

## Determining uploads

This function looks at the user inputs for calibration report collect and logs collected. Based on these inputs, it looks at all the uploaded logs or calibration reports and will print out what logs are missing and who to contact to get those files uploaded.

```{r}

source("src/mWater_collate/files_missing.R")

files_missing()

```

## Water Sampling Data:

Goal:

-   Save data in the correct format for RMRS spreadsheet

-   Save all water sampling probe values in a spreadsheet

```{r}
#source function
source("src/mWater_collate/sampling_spreadsheet_creator.R")
# To get the RMRS style data for a specfic date of sampling, 
# Input the date of interest in sampling_spreadsheet_creator
sampling_spreadsheet_creator(date_oi = "2023-10-16")

# To get all the water sampling data and save to CSV in sampling notes
# This also returns the df sampling_notes in case you want to review in R
sampling_spreadsheet_creator(all_dates = TRUE)
```

## Photos

Goal:

-   Download all user created photos ( upstream, downstream, clarity, filter and other pictures)

-   Label according to site, date, description in the format site_YYYYMMDD_descriptor.jpg

-   Only download photos which have not yet been downloaded

```{r}
source("src/mWater_collate/download_pictures.R")
  
#RUN TO DOWNLOAD NEW PICTURES
# It takes about 2-5 minutes to download ~25-50 photos

download_pictures()
        

```
